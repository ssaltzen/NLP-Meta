{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPMetaTest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMOHLxfAZi5Iokvn4U50Wj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssaltzen/NLP-Meta/blob/main/NLPMetaTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPquVGKmUnm_"
      },
      "source": [
        "# Imports/Installs "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_L87oj5Un6-",
        "outputId": "4aa9db33-a2ee-4781-cfbb-9af52b709b3b"
      },
      "source": [
        "%tensorflow_version 1.x\r\n",
        "!pip install -q gpt-2-simple\r\n",
        "import gpt_2_simple as gpt2\r\n",
        "from datetime import datetime\r\n",
        "from getpass import getpass\r\n",
        "from google.colab import files\r\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Thu Dec 17 22:23:37 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W82OY095VRPq"
      },
      "source": [
        "# Set up GPT2\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cWgdvS9VQIt"
      },
      "source": [
        "tempCorpus = \"tempCorpus.txt\"\r\n",
        "with open(tempCorpus, 'w') as f:\r\n",
        "\t\tf.write(corpus)\r\n",
        "\r\n",
        "gpt2.download_gpt2(model_name=\"124M\")\r\n",
        "\r\n",
        "sess = gpt2.start_tf_sess()\r\n",
        "\r\n",
        "gpt2.finetune(sess,\r\n",
        "              dataset= tempCorpus,\r\n",
        "              model_name='124M', \r\n",
        "              steps=1000,\r\n",
        "              )\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0hOUOInfc3y"
      },
      "source": [
        "ruleStartOp = {\" For every {} \":[\"keeps in mind {}\",\"is guided by the principle {}\",\"was chosen beacuse {}\",\"follows the principle {}\"],\r\n",
        "               \" Given each unique {} \": [\"keeps in mind {}\", \"is guided by the principle {}\", \"was chosen beacuse {}\", \"follows the principle {}\"],\r\n",
        "               \" The {} was placed \":[\"given {}\", \"to be representative of {}\", \"and follows the principle {}\"],\r\n",
        "               \" A {} was chosen \": [\"to display the rule {}\", \" and is guided by the principle {}\", \"to follow the principle {}\"],\r\n",
        "               \" This {} \":[\"keeps in mind {}\", \"is guided by the principle {}\", \"was chosen becuase {}\", \"follows the principle {}\"]}\r\n",
        "\r\n",
        "for item in associations:\r\n",
        "  thing = item[0]\r\n",
        "  thingRules = item[1]\r\n",
        "  if thingRules != tuple():\r\n",
        "    intro = choice(list(ruleStartOp.keys()))\r\n",
        "    tempBody = \"\" + ((intro).format(thing))\r\n",
        "    tempBody = tempBody + choice(ruleStartOp[intro]).format(rulesDescript[choice(thingRules)])\r\n",
        "\r\n",
        "    gpt2temp = gpt2.generate(sess, run_name='run1',\r\n",
        "              length=125,\r\n",
        "              temperature=0.65,\r\n",
        "              nsamples = 1,\r\n",
        "              prefix=tempBody,\r\n",
        "              return_as_list=True\r\n",
        "              )[0]\r\n",
        "\r\n",
        "    gpt2temp = gpt2temp[:gpt2temp.rindex('.')+1]\r\n",
        "    chronicle = chronicle + gpt2temp\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV6YV4MhsoP2"
      },
      "source": [
        "chronEndOP = [\"As you can see, the overall philosopy of this garden is \", \"This garden exists to \", \"Hopefully your tour through this garden leaves with feelings of \", \"This garden as a whole represents \"]\r\n",
        "\r\n",
        "lastgpt2 =  gpt2.generate(sess, run_name='run1',\r\n",
        "              length=50,\r\n",
        "              temperature=0.65,\r\n",
        "              nsamples = 1,\r\n",
        "              prefix=choice(chronEndOP),\r\n",
        "              return_as_list=True\r\n",
        "              )[0]\r\n",
        "\r\n",
        "lastgpt2 = lastgpt2[:lastgpt2.rindex('.')+1]\r\n",
        "\r\n",
        "chronicle = chronicle + lastgpt2\r\n",
        "\r\n",
        "print(chronicle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o9jGIsuU001"
      },
      "source": [
        "# Save Output to GitHub ZenCraft\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLlhzyj6i46S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09977812-8783-4d27-f61c-486787ccdc34"
      },
      "source": [
        "uname = \"ssaltzen\"\r\n",
        "from getpass import getpass\r\n",
        "password = getpass('Password:')\r\n",
        "\r\n",
        "!git config --global user.email '$uname@gmail.com'\r\n",
        "!git config --global user.name '$uname'\r\n",
        "\r\n",
        "!git clone https://$uname:$password@github.com/lukasmaxim/Zencraft.git\r\n",
        "\r\n",
        "%cd Zencraft/src/gpt2\r\n",
        "\r\n",
        "# create a file, then add it to stage\r\n",
        "f = open(\"output.txt\", \"w\")\r\n",
        "f.write(chronicle)\r\n",
        "f.close()\r\n",
        "\r\n",
        "\r\n",
        "!git add output.txt\r\n",
        "!git commit -m 'Zen Craft GPT2 Output Updated'  # commit in Colab\r\n",
        "!git push origin master  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Password:··········\n",
            "Cloning into 'Zencraft'...\n",
            "remote: Enumerating objects: 431, done.\u001b[K\n",
            "remote: Counting objects: 100% (431/431), done.\u001b[K\n",
            "remote: Compressing objects: 100% (226/226), done.\u001b[K\n",
            "remote: Total 431 (delta 267), reused 341 (delta 199), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (431/431), 392.61 KiB | 7.85 MiB/s, done.\n",
            "Resolving deltas: 100% (267/267), done.\n",
            "/content/Zencraft/src/gpt2\n",
            "[master 27d56f3] Zen Craft GPT2 Output Updated\n",
            " 1 file changed, 12 insertions(+), 6 deletions(-)\n",
            " rewrite src/gpt2/output.txt (100%)\n",
            "Counting objects: 5, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 1.82 KiB | 1.82 MiB/s, done.\n",
            "Total 5 (delta 3), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/lukasmaxim/Zencraft.git\n",
            "   6a7f733..27d56f3  master -> master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHK7hbO8kSzE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}